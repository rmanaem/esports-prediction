{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.dummy\n",
    "import sklearn.neighbors\n",
    "import sklearn.ensemble\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                         tier  game_duration  winning_team  first_champion  \\\nmatch_id                                                                     \nEUW1_5479661889        BRONZE           1797             1               1   \nEUW1_5479575964        BRONZE           1719             1               1   \nEUW1_5479499524        BRONZE           1352            -1              -1   \nEUW1_5479492935        BRONZE           1647            -1              -1   \nEUW1_5479357161        BRONZE           1509            -1              -1   \n...                       ...            ...           ...             ...   \nEUW1_5544360421  GRANDMASTERS           1928            -1               1   \nEUW1_5544335270  GRANDMASTERS           1101            -1              -1   \nEUW1_5544282724  GRANDMASTERS           1788             1              -1   \nEUW1_5544046900  GRANDMASTERS           2133             1              -1   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \n\n                 first_tower  first_inhibitor  first_baron  first_dragon  \nmatch_id                                                                  \nEUW1_5479661889            1                1            1             1  \nEUW1_5479575964           -1                1            0             1  \nEUW1_5479499524           -1               -1            0             1  \nEUW1_5479492935            1               -1            0            -1  \nEUW1_5479357161           -1               -1            0            -1  \n...                      ...              ...          ...           ...  \nEUW1_5544360421           -1               -1           -1             1  \nEUW1_5544335270           -1                0            0            -1  \nEUW1_5544282724            1                1            1            -1  \nEUW1_5544046900            1                1            1             1  \nEUW1_5543889504            1               -1           -1            -1  \n\n[36340 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tier</th>\n      <th>game_duration</th>\n      <th>winning_team</th>\n      <th>first_champion</th>\n      <th>first_tower</th>\n      <th>first_inhibitor</th>\n      <th>first_baron</th>\n      <th>first_dragon</th>\n    </tr>\n    <tr>\n      <th>match_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479575964</th>\n      <td>BRONZE</td>\n      <td>1719</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479499524</th>\n      <td>BRONZE</td>\n      <td>1352</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479492935</th>\n      <td>BRONZE</td>\n      <td>1647</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479357161</th>\n      <td>BRONZE</td>\n      <td>1509</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>EUW1_5544360421</th>\n      <td>GRANDMASTERS</td>\n      <td>1928</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5544335270</th>\n      <td>GRANDMASTERS</td>\n      <td>1101</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5544282724</th>\n      <td>GRANDMASTERS</td>\n      <td>1788</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5544046900</th>\n      <td>GRANDMASTERS</td>\n      <td>2133</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>36340 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read both the matches and the frames\n",
    "match_df = pd.read_csv('../output/csv/lol-data-matches-fixed-duration.csv')\n",
    "frame_df = pd.read_csv('../output/csv/lol-data-match-frames.csv')\n",
    "\n",
    "# set the index of the match id\n",
    "match_df = match_df.set_index('match_id')\n",
    "\n",
    "# Drop the columns we do not need\n",
    "match_df.drop(labels=['count','division','patch','region','first_rift_herald'], axis=1, inplace=True)\n",
    "\n",
    "# Fill all values that are not filled out\n",
    "match_df.fillna(0, inplace=True)\n",
    "\n",
    "# Remove any matches with no winning team\n",
    "match_df = match_df[match_df.winning_team!=0]\n",
    "\n",
    "# Change the IDs of blue side and red side to 1 and -1, respectively\n",
    "match_df.replace({\n",
    "    'winning_team': {100: 1, 200: -1},\n",
    "    'first_champion': {100: 1, 200: -1},\n",
    "    'first_tower': {100: 1, 200: -1},\n",
    "    'first_inhibitor': {100: 1, 200: -1},\n",
    "    'first_baron': {100: 1, 200: -1},\n",
    "    'first_dragon': {100: 1, 200: -1},\n",
    "}, inplace=True)\n",
    "\n",
    "# Reinterpret all values as int32s\n",
    "match_df = match_df.astype({\n",
    "    'winning_team': 'int32',\n",
    "    'first_champion': 'int32',\n",
    "    'first_tower': 'int32',\n",
    "    'first_inhibitor': 'int32',\n",
    "    'first_baron': 'int32',\n",
    "    'first_dragon': 'int32',\n",
    "})\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                         tier  game_duration  winning_team  first_champion  \\\nmatch_id                                                                     \nEUW1_5479661889        BRONZE           1797             1               1   \nEUW1_5479661889        BRONZE           1797             1               1   \nEUW1_5479661889        BRONZE           1797             1               1   \nEUW1_5479661889        BRONZE           1797             1               1   \nEUW1_5479661889        BRONZE           1797             1               1   \n...                       ...            ...           ...             ...   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \nEUW1_5543889504  GRANDMASTERS           1461            -1              -1   \n\n                 first_tower  first_inhibitor  first_baron  first_dragon  \\\nmatch_id                                                                   \nEUW1_5479661889            1                1            1             1   \nEUW1_5479661889            1                1            1             1   \nEUW1_5479661889            1                1            1             1   \nEUW1_5479661889            1                1            1             1   \nEUW1_5479661889            1                1            1             1   \n...                      ...              ...          ...           ...   \nEUW1_5543889504            1               -1           -1            -1   \nEUW1_5543889504            1               -1           -1            -1   \nEUW1_5543889504            1               -1           -1            -1   \nEUW1_5543889504            1               -1           -1            -1   \nEUW1_5543889504            1               -1           -1            -1   \n\n                  count  frame  ...  red_total_kills  red_total_gold  \\\nmatch_id                        ...                                    \nEUW1_5479661889   80697      0  ...                0            2500   \nEUW1_5479661889   80698      1  ...                0            2500   \nEUW1_5479661889   80699      2  ...                0            2889   \nEUW1_5479661889   80700      3  ...                0            4423   \nEUW1_5479661889   80701      4  ...                0            5701   \n...                 ...    ...  ...              ...             ...   \nEUW1_5543889504  824350     21  ...               27           48140   \nEUW1_5543889504  824351     22  ...               27           52429   \nEUW1_5543889504  824352     23  ...               32           54304   \nEUW1_5543889504  824353     24  ...               32           57442   \nEUW1_5543889504  824354     25  ...               36           60033   \n\n                 red_total_cs  red_total_damage  red_towers  red_plates  \\\nmatch_id                                                                  \nEUW1_5479661889             0                 0           0           0   \nEUW1_5479661889             0                 0           0           0   \nEUW1_5479661889            13               323           0           0   \nEUW1_5479661889            53              1785           0           0   \nEUW1_5479661889            79              2828           0           0   \n...                       ...               ...         ...         ...   \nEUW1_5543889504           724             52148           2          11   \nEUW1_5543889504           758             61645           2          11   \nEUW1_5543889504           773             69206           2          11   \nEUW1_5543889504           793             76620           2          11   \nEUW1_5543889504           807             82744           2          11   \n\n                 red_inhibitors  red_barons  red_dragons  red_rift_heralds  \nmatch_id                                                                    \nEUW1_5479661889               0           0            0                 0  \nEUW1_5479661889               0           0            0                 0  \nEUW1_5479661889               0           0            0                 0  \nEUW1_5479661889               0           0            0                 0  \nEUW1_5479661889               0           0            0                 0  \n...                         ...         ...          ...               ...  \nEUW1_5543889504               0           0            3                 1  \nEUW1_5543889504               0           1            3                 1  \nEUW1_5543889504               0           1            3                 1  \nEUW1_5543889504               0           1            3                 1  \nEUW1_5543889504               0           1            3                 1  \n\n[1082484 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tier</th>\n      <th>game_duration</th>\n      <th>winning_team</th>\n      <th>first_champion</th>\n      <th>first_tower</th>\n      <th>first_inhibitor</th>\n      <th>first_baron</th>\n      <th>first_dragon</th>\n      <th>count</th>\n      <th>frame</th>\n      <th>...</th>\n      <th>red_total_kills</th>\n      <th>red_total_gold</th>\n      <th>red_total_cs</th>\n      <th>red_total_damage</th>\n      <th>red_towers</th>\n      <th>red_plates</th>\n      <th>red_inhibitors</th>\n      <th>red_barons</th>\n      <th>red_dragons</th>\n      <th>red_rift_heralds</th>\n    </tr>\n    <tr>\n      <th>match_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>80697</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>80698</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>80699</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2889</td>\n      <td>13</td>\n      <td>323</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>80700</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4423</td>\n      <td>53</td>\n      <td>1785</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EUW1_5479661889</th>\n      <td>BRONZE</td>\n      <td>1797</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>80701</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5701</td>\n      <td>79</td>\n      <td>2828</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>824350</td>\n      <td>21</td>\n      <td>...</td>\n      <td>27</td>\n      <td>48140</td>\n      <td>724</td>\n      <td>52148</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>824351</td>\n      <td>22</td>\n      <td>...</td>\n      <td>27</td>\n      <td>52429</td>\n      <td>758</td>\n      <td>61645</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>824352</td>\n      <td>23</td>\n      <td>...</td>\n      <td>32</td>\n      <td>54304</td>\n      <td>773</td>\n      <td>69206</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>824353</td>\n      <td>24</td>\n      <td>...</td>\n      <td>32</td>\n      <td>57442</td>\n      <td>793</td>\n      <td>76620</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>EUW1_5543889504</th>\n      <td>GRANDMASTERS</td>\n      <td>1461</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>824354</td>\n      <td>25</td>\n      <td>...</td>\n      <td>36</td>\n      <td>60033</td>\n      <td>807</td>\n      <td>82744</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1082484 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the match dataframe and the frame dataframe into one common table\n",
    "df = match_df.merge(frame_df,left_on='match_id', right_on='match_id').set_index('match_id')\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we train a dummy classifier to compare performance\n",
    "\n",
    "def train_dummy_classifier(X, y):\n",
    "    X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "    dummy_clf = sklearn.dummy.DummyClassifier(strategy='uniform', random_state=0)\n",
    "    # Scale the data with MinMax to avoid negative values\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_trn)\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_tst = scaler.transform(X_tst)\n",
    "\n",
    "    dummy_clf.fit(X_trn,y_trn)\n",
    "    print(dummy_clf.score(X_tst, y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ON FRAME #25\n"
     ]
    }
   ],
   "source": [
    "# Loop created to go through every frame in the data set. \n",
    "# For each frame, pick all corresponding data points, and \n",
    "# train both the neural network and the dummy classifier\n",
    "# with it\n",
    "current_frame = 25\n",
    "\n",
    "print(\"TRAINING ON FRAME #%i\" % current_frame)\n",
    "# Get the values of X and y for a given frame\n",
    "X = df[df.frame==current_frame][[\n",
    "    'blue_total_kills',\n",
    "    'blue_total_gold',\n",
    "    'blue_total_cs',\n",
    "    'blue_total_damage',\n",
    "    'blue_towers', \n",
    "    'blue_plates',\n",
    "    'blue_inhibitors', \n",
    "    'blue_barons', \n",
    "    'blue_dragons', \n",
    "    'blue_rift_heralds',\n",
    "    'red_total_kills', \n",
    "    'red_total_gold', \n",
    "    'red_total_cs', \n",
    "    'red_total_damage',\n",
    "    'red_towers', \n",
    "    'red_plates', \n",
    "    'red_inhibitors', \n",
    "    'red_barons',\n",
    "    'red_dragons', \n",
    "    'red_rift_heralds',\n",
    "]].values\n",
    "y = df[df.frame==current_frame]['winning_team'].values\n",
    "\n",
    "# Convert -1 and +1 to 0 and 1 for the tensors to work\n",
    "y = np.interp(y, (-1,+1), (0, 1)).astype(np.int32)\n",
    "\n",
    "# Two things occur here:\n",
    "# 1. Normalize the data from values to a distribution [0,1] in l1 norm\n",
    "#    e.g if Red side has 11 kill, and Blue has 9, we represent it as\n",
    "#        0.55 and 0.45, respectively.\n",
    "# 2. Collapse each blue features to their red features by subtracting them\n",
    "#    e.g for ourprevious example, subtracting blue from red would result\n",
    "#        to having 0.55-0.45 = 0.1. Hence a 10% advantage for blue\n",
    "#        FIXME: could be an arbitrary x[0,:] - 0.5 to avoid doubling up\n",
    "def combine(x):\n",
    "    x = sklearn.preprocessing.normalize(x.reshape(2,10), norm='l1', axis=0)\n",
    "    return x.reshape(20)\n",
    "# Normalize the data to have 10 features \n",
    "# corresponding to a better comparison.\n",
    "X = np.apply_along_axis(combine, 1, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "#Split data\n",
    "X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def score_estimators(X, y, estimators):\n",
    "    \"\"\"Scores each estimator on (X, y), returning a list of scores.\"\"\"\n",
    "    # Your implementation here. Aim for 1-4 lines.\n",
    "    scores = np.zeros_like(estimators)\n",
    "    for x in range(len(estimators)):\n",
    "        scores[x] = sklearn.metrics.accuracy_score(y, estimators[x].predict(X))\n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def plot_estimator_scores(estimators, param_name, param_vals):\n",
    "    \"\"\"\n",
    "    Plots the training, validation, and testing scores of a list of estimators,\n",
    "    where `param_name` and `param_vals` are the same as for `train_estimators`.\n",
    "    The estimator with best validation score will be highlighted with an 'x'.\n",
    "    \"\"\"\n",
    "    # Your implementation here. Use as many lines as you need\n",
    "    plt.figure()\n",
    "    X = np.arange(0, len(param_vals))\n",
    "    trn_scores = score_estimators(X_trn, y_trn, estimators)\n",
    "    tst_scores = score_estimators(X_tst, y_tst, estimators)\n",
    "    index = np.argmin(trn_scores - tst_scores)\n",
    "    print(tst_scores[index])\n",
    "    plt.title(estimators[0].__class__.__name__ + \" score vs \" + param_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.ylim(0.0, 1.05)\n",
    "    plt.scatter(X[index], tst_scores[index], marker='x', color='black', s=200)\n",
    "    plt.plot(X, trn_scores, marker='o', color='green', markerfacecolor='green', label=\"train\")\n",
    "    plt.plot(X, tst_scores, marker='o', color='red', markerfacecolor='red', label=\"test\")\n",
    "    plt.text(0, 0.4,\n",
    "             \"Optimal Test Accuracy = %.2f%% with %s = %d \" % (tst_scores[index] * 100, param_name, param_vals[index]))\n",
    "    plt.legend()\n",
    "    plt.xticks(X, param_vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "\n",
    "def train_estimators(X, y, estimator_type, param_name, param_vals, **kwargs):\n",
    "    estimators = [0 for i in range(len(param_vals))]\n",
    "    for x in range(len(param_vals)):\n",
    "        estimators[x] = estimator_type(**{param_name: param_vals[x]}, **kwargs).fit(X, y)\n",
    "        # Training DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random')...\n",
    "        print(\"Training \" + estimator_type.__name__ + \"(\" + param_name + \"=%d \" % param_vals[x] + \" {0}={1} \".format(\n",
    "            kwargs.keys(), kwargs.values()))\n",
    "    return estimators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def train_kNN_estimators(X, y):\n",
    "    #X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "    param_vals = [1, 5, 10, 15, 20]\n",
    "\n",
    "    knn_estimators = train_estimators(X_trn, y_trn, sklearn.neighbors.KNeighborsClassifier, 'n_neighbors',\n",
    "                                      param_vals=param_vals)\n",
    "\n",
    "    plot_estimator_scores(knn_estimators, param_name='n_neighbors', param_vals=param_vals)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "\n",
    "def train_random_forests(X, y):\n",
    "    X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    X_trn = scaler.fit_transform(X_trn)\n",
    "    X_tst = scaler.fit_transform(X_tst)\n",
    "    estimator = np.arange(1, 6) * 50\n",
    "    depths = np.arange(1, 6) * 5\n",
    "    estimators_meshed, depths_meshed = np.meshgrid(estimator, depths)\n",
    "\n",
    "    trn_scores = np.arange(0, 25, dtype=float)\n",
    "    tst_scores = np.arange(0, 25, dtype=float)\n",
    "    X_axis = np.arange(0, 25)\n",
    "    para_vals = np.array(\n",
    "        [\"50:5\", \"50:10\", \"50:15\", \"50:20\", \"50:25\", \"100:5\", \"100:10\", \"100:15\", \"100:20\", \"100:25\", \"150:5\", \"150:10\",\n",
    "         \"150:15\", \"150:20\", \"150:25\", \"200:5\", \"200:10\", \"200:15\", \"200:20\", \"200:25\", \"250:5\", \"250:10\", \"250:15\",\n",
    "         \"250:20\", \"250:25\"])\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            random_forest_model = sklearn.ensemble.RandomForestClassifier(n_estimators=estimators_meshed[j][i],\n",
    "                                                                          max_depth=depths_meshed[j][i],\n",
    "                                                                          random_state=0).fit(X_trn, y_trn)\n",
    "            trn_scores[i * 5 + j] = sklearn.metrics.accuracy_score(y_trn, random_forest_model.predict(X_trn))\n",
    "            print(\"Training Accuracy: %.2f %% with estimators = %d , depth = %d \\n\" % (\n",
    "                trn_scores[i * 5 + j] * 100, estimators_meshed[j][i], depths_meshed[j][i]))\n",
    "            tst_scores[i * 5 + j] = sklearn.metrics.accuracy_score(y_tst, random_forest_model.predict(X_tst))\n",
    "            print(\"Test Accuracy: %.2f %% with estimators = %d , depth = %d \\n\" % (\n",
    "                tst_scores[i * 5 + j] * 100, estimators_meshed[j][i], depths_meshed[j][i]))\n",
    "    plt.figure()\n",
    "    plt.title(\"Random Forests score vs estimators : depth\")\n",
    "    plt.xlabel(\"estimators : depth\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.ylim(0.0, 1.05)\n",
    "    index = np.argmin(trn_scores - tst_scores)\n",
    "    plt.scatter(X_axis[index], trn_scores[index], marker='x', color='black', s=200)\n",
    "    plt.plot(X_axis, trn_scores, marker='o', color='green', markerfacecolor='green', label=\"train\")\n",
    "    plt.plot(X_axis, tst_scores, marker='o', color='red', markerfacecolor='red', label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.text(0, 0.4,\n",
    "             \"Optimal Test Accuracy = %.2f%% with estimators : depth = %s \" % (tst_scores[index] * 100, para_vals[index]))\n",
    "    plt.xticks(X_axis, para_vals, fontsize=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the neural network trained in Lab 8\n",
    "\n",
    "def train_neural_network(X, y):\n",
    "    # Split the data 2/3 to 1/3\n",
    "    X_trn, X_tst, y_trn, y_tst = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "    # Scale the data with MinMax to avoid negative values\n",
    "    print(X_trn.shape)\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(X_trn)\n",
    "    X_trn = scaler.transform(X_trn)\n",
    "    X_tst = scaler.transform(X_tst)\n",
    "\n",
    "    # Tensors setup\n",
    "    X_trn_torch = torch.tensor(X_trn, dtype=torch.float32)\n",
    "    y_trn_torch = torch.tensor(y_trn, dtype=torch.int64)\n",
    "    X_tst_torch = torch.tensor(X_tst, dtype=torch.float32)\n",
    "    y_tst_torch = torch.tensor(y_tst, dtype=torch.int64)\n",
    "\n",
    "    torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "    # Create an object that holds a sequence of layers and activation functions\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(20, 10),   # Applies Wx+b from 10 dimensions down to 2\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(10,2)\n",
    "    )\n",
    "\n",
    "    # Create an object that can compute \"negative log likelihood of a softmax\"\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use stochastic gradient descent to train the model\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # Use 100 training samples at a time to compute the gradient.\n",
    "    batch_size = 200\n",
    "\n",
    "    # Make 10 passes over the training data, each time using batch_size samples to compute gradient\n",
    "    num_epoch = 10\n",
    "    next_epoch = 1\n",
    "\n",
    "    for epoch in range(next_epoch, next_epoch+num_epoch):\n",
    "        # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
    "        for i in range(0, len(X_trn), batch_size):        \n",
    "            X_cur = X_trn_torch[i:i+batch_size]     # Slice out a mini-batch of features\n",
    "            y_cur = y_trn_torch[i:i+batch_size]     # Slice out a mini-batch of targets\n",
    "            \n",
    "            y_pred = model(X_cur)                   # Make predictions (final-layer activations)\n",
    "            l = loss(y_pred, y_cur)                 # Compute loss with respect to predictions\n",
    "            \n",
    "            model.zero_grad()                   # Reset all gradient accumulators to zero (PyTorch thing)\n",
    "            l.backward()                        # Compute gradient of loss wrt all parameters (backprop!)\n",
    "            optimizer.step()                    # Use the gradients to take a step with SGD.\n",
    "            \n",
    "        print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
    "        \n",
    "    print(\"Epoch %2d: loss on test set: %.4f\" % (epoch, loss(model(X_tst_torch), y_tst_torch)))\n",
    "    next_epoch = epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 83.15 % with estimators = 50 , depth = 5 \n",
      "\n",
      "Test Accuracy: 82.46 % with estimators = 50 , depth = 5 \n",
      "\n",
      "Training Accuracy: 88.67 % with estimators = 50 , depth = 10 \n",
      "\n",
      "Test Accuracy: 82.25 % with estimators = 50 , depth = 10 \n",
      "\n",
      "Training Accuracy: 98.01 % with estimators = 50 , depth = 15 \n",
      "\n",
      "Test Accuracy: 81.85 % with estimators = 50 , depth = 15 \n",
      "\n",
      "Training Accuracy: 99.89 % with estimators = 50 , depth = 20 \n",
      "\n",
      "Test Accuracy: 82.08 % with estimators = 50 , depth = 20 \n",
      "\n",
      "Training Accuracy: 99.96 % with estimators = 50 , depth = 25 \n",
      "\n",
      "Test Accuracy: 81.71 % with estimators = 50 , depth = 25 \n",
      "\n",
      "Training Accuracy: 83.17 % with estimators = 100 , depth = 5 \n",
      "\n",
      "Test Accuracy: 82.64 % with estimators = 100 , depth = 5 \n",
      "\n",
      "Training Accuracy: 88.83 % with estimators = 100 , depth = 10 \n",
      "\n",
      "Test Accuracy: 82.56 % with estimators = 100 , depth = 10 \n",
      "\n",
      "Training Accuracy: 98.17 % with estimators = 100 , depth = 15 \n",
      "\n",
      "Test Accuracy: 82.03 % with estimators = 100 , depth = 15 \n",
      "\n",
      "Training Accuracy: 99.98 % with estimators = 100 , depth = 20 \n",
      "\n",
      "Test Accuracy: 82.15 % with estimators = 100 , depth = 20 \n",
      "\n",
      "Training Accuracy: 99.99 % with estimators = 100 , depth = 25 \n",
      "\n",
      "Test Accuracy: 82.15 % with estimators = 100 , depth = 25 \n",
      "\n",
      "Training Accuracy: 83.19 % with estimators = 150 , depth = 5 \n",
      "\n",
      "Test Accuracy: 82.73 % with estimators = 150 , depth = 5 \n",
      "\n",
      "Training Accuracy: 88.77 % with estimators = 150 , depth = 10 \n",
      "\n",
      "Test Accuracy: 82.55 % with estimators = 150 , depth = 10 \n",
      "\n",
      "Training Accuracy: 98.15 % with estimators = 150 , depth = 15 \n",
      "\n",
      "Test Accuracy: 82.21 % with estimators = 150 , depth = 15 \n",
      "\n",
      "Training Accuracy: 99.99 % with estimators = 150 , depth = 20 \n",
      "\n",
      "Test Accuracy: 82.05 % with estimators = 150 , depth = 20 \n",
      "\n",
      "Training Accuracy: 99.99 % with estimators = 150 , depth = 25 \n",
      "\n",
      "Test Accuracy: 82.02 % with estimators = 150 , depth = 25 \n",
      "\n",
      "Training Accuracy: 83.23 % with estimators = 200 , depth = 5 \n",
      "\n",
      "Test Accuracy: 82.74 % with estimators = 200 , depth = 5 \n",
      "\n",
      "Training Accuracy: 88.80 % with estimators = 200 , depth = 10 \n",
      "\n",
      "Test Accuracy: 82.63 % with estimators = 200 , depth = 10 \n",
      "\n",
      "Training Accuracy: 98.27 % with estimators = 200 , depth = 15 \n",
      "\n",
      "Test Accuracy: 82.25 % with estimators = 200 , depth = 15 \n",
      "\n",
      "Training Accuracy: 100.00 % with estimators = 200 , depth = 20 \n",
      "\n",
      "Test Accuracy: 82.10 % with estimators = 200 , depth = 20 \n",
      "\n",
      "Training Accuracy: 100.00 % with estimators = 200 , depth = 25 \n",
      "\n",
      "Test Accuracy: 82.17 % with estimators = 200 , depth = 25 \n",
      "\n",
      "Training Accuracy: 83.16 % with estimators = 250 , depth = 5 \n",
      "\n",
      "Test Accuracy: 82.77 % with estimators = 250 , depth = 5 \n",
      "\n",
      "Training Accuracy: 88.84 % with estimators = 250 , depth = 10 \n",
      "\n",
      "Test Accuracy: 82.57 % with estimators = 250 , depth = 10 \n",
      "\n",
      "Training Accuracy: 98.24 % with estimators = 250 , depth = 15 \n",
      "\n",
      "Test Accuracy: 82.12 % with estimators = 250 , depth = 15 \n",
      "\n",
      "Training Accuracy: 100.00 % with estimators = 250 , depth = 20 \n",
      "\n",
      "Test Accuracy: 82.27 % with estimators = 250 , depth = 20 \n",
      "\n",
      "Training Accuracy: 100.00 % with estimators = 250 , depth = 25 \n",
      "\n",
      "Test Accuracy: 82.07 % with estimators = 250 , depth = 25 \n",
      "\n",
      "['50:5' '50:10' '50:15' '50:20' '50:25' '100:5' '100:10' '100:15' '100:20'\n",
      " '100:25' '150:5' '150:10' '150:15' '150:20' '150:25' '200:5' '200:10'\n",
      " '200:15' '200:20' '200:25' '250:5' '250:10' '250:15' '250:20' '250:25']\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_neural_network(X, y)\n",
    "#train_kNN_estimators(X, y)\n",
    "train_random_forests(X, y)\n",
    "# train_dummy_classifier(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "pycharm-1b24e8a1",
   "language": "python",
   "display_name": "PyCharm (comp432)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}